{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow.keras as keras\n",
    "    import tensorflow.keras.backend as K\n",
    "except:\n",
    "    import keras\n",
    "    import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from .utils import set_momentum, set_lr\n",
    "\n",
    "\n",
    "class OneCycle(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A callback class for one-cycle policy training.\n",
    "\n",
    "    :param lr_range: a tuple of starting (usually minimum) lr value and maximum (peak) lr value.\n",
    "    :param momentum_range: a tuple of momentum values.\n",
    "    :param phase_one_fraction: a fraction for phase I (increasing lr) in one cycle. Must between 0 to 1.\n",
    "    :param reset_on_train_begin: True or False to reset counters when training begins.\n",
    "    :param record_frq: integer > 0, a frequency in batches to record training loss.\n",
    "    :param verbose: True or False to print progress.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            lr_range,\n",
    "            momentum_range=None,\n",
    "            phase_one_fraction=0.3,\n",
    "            reset_on_train_begin=True,\n",
    "            record_frq=10,\n",
    "            verbose=False):\n",
    "\n",
    "        super(OneCycle, self).__init__()\n",
    "\n",
    "        self.lr_range = lr_range\n",
    "\n",
    "        self.momentum_range = momentum_range\n",
    "        if momentum_range is not None:\n",
    "            err_msg = \"momentum_range must be a 2-numeric tuple (m1, m2).\"\n",
    "            if not isinstance(momentum_range, (tuple,)) or len(momentum_range) != 2:\n",
    "                raise ValueError(err_msg)\n",
    "\n",
    "        self.phase_one_fraction = phase_one_fraction\n",
    "        self.reset_on_train_begin = reset_on_train_begin\n",
    "        self.record_frq = record_frq\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # helper tracker\n",
    "        self.log = {}  # history in iterations\n",
    "        self.log_ep = {}  # history in epochs\n",
    "        self.stop_training = False\n",
    "\n",
    "        # counter\n",
    "        self.current_iter = 0\n",
    "\n",
    "    def get_current_lr(self, n_iter=None):\n",
    "        \"\"\"\n",
    "        A helper function to calculate a current learning rate based on current iteration number.\n",
    "\n",
    "        :return lr: a current learning rate.\n",
    "        \"\"\"\n",
    "        if n_iter is None:\n",
    "            n_iter = self.n_iter\n",
    "\n",
    "        x = float(self.current_iter) / n_iter\n",
    "        if x < self.phase_one_fraction:\n",
    "            amp = self.lr_range[1] - self.lr_range[0]\n",
    "            lr = (np.cos(x * np.pi/self.phase_one_fraction - np.pi) + 1) * amp / 2.0 + self.lr_range[0]\n",
    "        if x >= self.phase_one_fraction:\n",
    "            amp = self.lr_range[1]\n",
    "            lr = (np.cos((x - self.phase_one_fraction) * np.pi/ (1-self.phase_one_fraction)) + 1) / 2.0 * amp\n",
    "        return lr\n",
    "\n",
    "    def get_current_momentum(self, n_iter=None):\n",
    "        \"\"\"\n",
    "        A helper function to calculate a current momentum based on current iteration number.\n",
    "\n",
    "        :return momentum: a current momentum.\n",
    "        \"\"\"\n",
    "        if n_iter is None:\n",
    "            n_iter = self.n_iter\n",
    "        amp = self.momentum_range[1] - self.momentum_range[0]\n",
    "        # delta = (1 - np.abs(np.mod(self.current_iter, n_iter) * 2.0 / n_iter - 1)) * amplitude\n",
    "        x = float(self.current_iter) / n_iter\n",
    "        if x < self.phase_one_fraction:\n",
    "            delta = (np.cos(x * np.pi / self.phase_one_fraction - np.pi) + 1) * amp / 2.0\n",
    "        if x >= self.phase_one_fraction:\n",
    "            delta = (np.cos((x - self.phase_one_fraction) * np.pi / (1 - self.phase_one_fraction)) + 1) / 2.0 * amp\n",
    "        return delta + self.momentum_range[0]\n",
    "\n",
    "\n",
    "    @property\n",
    "    def cycle_momentum(self):\n",
    "        return self.momentum_range is not None\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.n_epoch = self.params['epochs']\n",
    "\n",
    "        # find number of batches per epoch\n",
    "        if self.params['batch_size'] is not None:  # model.fit\n",
    "            self.n_bpe = int(np.ceil(self.params['samples'] / self.params['batch_size']))\n",
    "        if self.params['batch_size'] is None:  # model.fit_generator\n",
    "            self.n_bpe = self.params['samples']\n",
    "\n",
    "        self.n_iter = self.n_epoch * self.n_bpe\n",
    "        # this is a number of iteration in one cycle\n",
    "\n",
    "        self.current_iter = 0\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs={}):\n",
    "        set_lr(self.model.optimizer, self.get_current_lr())\n",
    "        if self.cycle_momentum:\n",
    "            set_momentum(self.model.optimizer, self.get_current_momentum())\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs={}):\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"lr={:.2e}\".format(self.get_current_lr()), \",\", \"m={:.2e}\".format(self.get_current_momentum()))\n",
    "\n",
    "        # record according to record_frq\n",
    "        if np.mod(int(self.current_iter), self.record_frq) == 0:\n",
    "            self.log.setdefault('lr', []).append(self.get_current_lr())\n",
    "            if self.cycle_momentum:\n",
    "                self.log.setdefault('momentum', []).append(self.get_current_momentum())\n",
    "\n",
    "            for k, v in logs.items():\n",
    "                self.log.setdefault(k, []).append(v)\n",
    "\n",
    "            self.log.setdefault('iter', []).append(self.current_iter)\n",
    "\n",
    "        # update current iteration\n",
    "        self.current_iter += 1\n",
    "\n",
    "        # consider termination\n",
    "        if self.current_iter == self.n_iter:\n",
    "            self.stop_training = True\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.log_ep.setdefault('epoch', []).append(epoch)\n",
    "        self.log_ep.setdefault('lr', []).append(\n",
    "            K.get_value(self.model.optimizer.lr))\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.log_ep.setdefault(k, []).append(v)\n",
    "\n",
    "    def test_run(self, n_iter=None):\n",
    "        \"\"\"\n",
    "        Visualize values of learning rate (and momentum) as a function of iteration (batch).\n",
    "\n",
    "        :param n_iter: a number of cycles. If None, 1000 is used.\n",
    "        \"\"\"\n",
    "\n",
    "        if hasattr(self, 'current_iter'):\n",
    "            original_it = self.current_iter\n",
    "\n",
    "        if n_iter is None:\n",
    "            if hasattr(self, 'n_iter'):\n",
    "                n_iter = self.n_iter\n",
    "            else:\n",
    "                n_iter = 1000\n",
    "        n_iter = int(n_iter)\n",
    "\n",
    "        lrs = np.zeros(shape=(n_iter,))\n",
    "        if self.momentum_range is not None:\n",
    "            moms = np.zeros_like(lrs)\n",
    "\n",
    "        for i in range(int(n_iter)):\n",
    "            self.current_iter = i\n",
    "            lrs[i] = self.get_current_lr(n_iter)\n",
    "            if self.cycle_momentum:\n",
    "                moms[i] = self.get_current_momentum(n_iter)\n",
    "        if not self.cycle_momentum:\n",
    "            plt.plot(lrs)\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('lr')\n",
    "        else:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(lrs)\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('lr')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(moms)\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('momentum')\n",
    "\n",
    "        if hasattr(self, 'current_iter'):\n",
    "            self.current_iter = original_it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac3e17e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
