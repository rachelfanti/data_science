{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 05 Deep Learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "LECTURE_ID = \"05\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", LECTURE_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Train a deep MLP on the MNIST dataset (you can load it using `keras.datasets.mnist.load_data()`. See if you can get over 98% precision. Try adding all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to carry out:\n",
    "- load the dataset \n",
    "- explore dataset and normalise it\n",
    "- define the NN model\n",
    "- compile the model\n",
    "- evaluate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape\n",
    "y_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set & Normalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "# keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\",kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\",kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 5s 97us/sample - loss: 0.5851 - accuracy: 0.8450 - val_loss: 0.2950 - val_accuracy: 0.9194\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.2764 - accuracy: 0.9215 - val_loss: 0.2385 - val_accuracy: 0.9320\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.2258 - accuracy: 0.9358 - val_loss: 0.1960 - val_accuracy: 0.9432\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 6s 106us/sample - loss: 0.1929 - accuracy: 0.9453 - val_loss: 0.1734 - val_accuracy: 0.9528\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.1682 - accuracy: 0.9522 - val_loss: 0.1565 - val_accuracy: 0.9574\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.1496 - accuracy: 0.9574 - val_loss: 0.1428 - val_accuracy: 0.9624\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 5s 94us/sample - loss: 0.1340 - accuracy: 0.9620 - val_loss: 0.1299 - val_accuracy: 0.9634\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.1212 - accuracy: 0.9659 - val_loss: 0.1249 - val_accuracy: 0.9666\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.1103 - accuracy: 0.9689 - val_loss: 0.1161 - val_accuracy: 0.9680\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 6s 105us/sample - loss: 0.1007 - accuracy: 0.9715 - val_loss: 0.1115 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 5s 97us/sample - loss: 0.0928 - accuracy: 0.9742 - val_loss: 0.1037 - val_accuracy: 0.9716\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 6s 101us/sample - loss: 0.0856 - accuracy: 0.9754 - val_loss: 0.0988 - val_accuracy: 0.9728\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.0792 - accuracy: 0.9779 - val_loss: 0.0941 - val_accuracy: 0.9740\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0739 - accuracy: 0.9794 - val_loss: 0.0926 - val_accuracy: 0.9756\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.0684 - accuracy: 0.9816 - val_loss: 0.0913 - val_accuracy: 0.9746\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.0635 - accuracy: 0.9827 - val_loss: 0.0848 - val_accuracy: 0.9744\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0595 - accuracy: 0.9839 - val_loss: 0.0872 - val_accuracy: 0.9750\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.0556 - accuracy: 0.9849 - val_loss: 0.0807 - val_accuracy: 0.9766\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 6s 104us/sample - loss: 0.0520 - accuracy: 0.9867 - val_loss: 0.0810 - val_accuracy: 0.9762\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 5s 97us/sample - loss: 0.0487 - accuracy: 0.9876 - val_loss: 0.0801 - val_accuracy: 0.9782\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.0458 - accuracy: 0.9883 - val_loss: 0.0771 - val_accuracy: 0.9782\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 6s 104us/sample - loss: 0.0428 - accuracy: 0.9889 - val_loss: 0.0772 - val_accuracy: 0.9786\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 6s 104us/sample - loss: 0.0402 - accuracy: 0.9898 - val_loss: 0.0756 - val_accuracy: 0.9776\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.0379 - accuracy: 0.9903 - val_loss: 0.0760 - val_accuracy: 0.9770\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 6s 110us/sample - loss: 0.0357 - accuracy: 0.9911 - val_loss: 0.0733 - val_accuracy: 0.9790\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.0335 - accuracy: 0.9917 - val_loss: 0.0727 - val_accuracy: 0.9802\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.0314 - accuracy: 0.9927 - val_loss: 0.0720 - val_accuracy: 0.9794\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.0295 - accuracy: 0.9935 - val_loss: 0.0731 - val_accuracy: 0.9776\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.0276 - accuracy: 0.9940 - val_loss: 0.0719 - val_accuracy: 0.9800\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 6s 105us/sample - loss: 0.0261 - accuracy: 0.9945 - val_loss: 0.0728 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, 'myminst_logs','run_{:03d}'.format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=./myminst_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.0712 - accuracy: 0.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07118143979699816, 0.978]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
